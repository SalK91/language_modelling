<!DOCTYPE html><html lang="en" class="no-js"><head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Structured lecture notes on Natural Language Processing.">
      
      
        <meta name="author" content="Salman Khan">
      
      
        <link rel="canonical" href="https://salk91.github.io/language_modelling/nlp/22_llm_training_basics/">
      
      
        <link rel="prev" href="../21_advanced_topics/">
      
      
        <link rel="next" href="../23_reasoning/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.20">
    
    
      
        <title>22. LLM Training Basics - NLP Lecture Notes</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.e53b48f4.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Merriweather:300,300i,400,400i,700,700i%7CFira+Code:400,400i,700,700i&amp;display=fallback">
        <style>:root{--md-text-font:"Merriweather";--md-code-font:"Fira Code"}</style>
      
    
    
      <link rel="stylesheet" href="../../css/print-site.css">
    
      <link rel="stylesheet" href="../../css/print-site-material.css">
    
      <link rel="stylesheet" href="../../styles/extra.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  <link href="../../assets/stylesheets/glightbox.min.css" rel="stylesheet"><script src="../../assets/javascripts/glightbox.min.js"></script><style id="glightbox-style">
            html.glightbox-open { overflow: initial; height: 100%; }
            .gslide-title { margin-top: 0px; user-select: text; }
            .gslide-desc { color: #666; user-select: text; }
            .gslide-image img { background: white; }
            .gscrollbar-fixer { padding-right: 15px; }
            .gdesc-inner { font-size: 0.75rem; }
            body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color); }
            body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color); }
            body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color); }
        </style></head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="cyan">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="NLP Lecture Notes" class="md-header__button md-logo" aria-label="NLP Lecture Notes" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"></path></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"></path></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            NLP Lecture Notes
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              22. LLM Training Basics
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="cyan" aria-label="Switch to dark mode" type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"></path></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="cyan" aria-label="Switch to light mode" type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m3.55 19.09 1.41 1.41 1.8-1.79-1.42-1.42M12 6c-3.31 0-6 2.69-6 6s2.69 6 6 6 6-2.69 6-6c0-3.32-2.69-6-6-6m8 7h3v-2h-3m-2.76 7.71 1.8 1.79 1.41-1.41-1.79-1.8M20.45 5l-1.41-1.4-1.8 1.79 1.42 1.42M13 1h-2v3h2M6.76 5.39 4.96 3.6 3.55 5l1.79 1.81zM1 13h3v-2H1m12 9h-2v3h2"></path></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/SalK91/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"></path></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../1_intro/" class="md-tabs__link">
          
  
  
    
  
  Natural Language Processing

        </a>
      </li>
    
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../print_page/" class="md-tabs__link">
        
  
  
    
  
  Print/PDF

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="NLP Lecture Notes" class="md-nav__button md-logo" aria-label="NLP Lecture Notes" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"></path></svg>

    </a>
    NLP Lecture Notes
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/SalK91/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"></path></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Natural Language Processing
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Natural Language Processing
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1_intro/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    1. NLP an introduction
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2_lmnp/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2. Language Models and Word Sequence Probability
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../3_nn/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3. Window-based Neural Language Models
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../4_rnn/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    4. Recurrent Neural Networks
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../5_lstm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    5. Long Short-Term Memory (LSTM) Networks
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../6_app_rnn/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    6. Applications of RNN
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../7_eval_nlp/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    7. Evaluation of Language Models
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../8_attention_seq2seq/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    8. Attention Mechanism in Sequence-to-Sequence Models
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../9_selfattention/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    9. Self- Attention
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../10_archi/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    10. Transformer Architectures
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../11_tokens/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    11. Tokenization
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../12_pretraining/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    12. Pre-training
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../13_pretrain_strat/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    13. Pre-training Strategies
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../14_finetuning/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    14. Fine-tuning
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../15_cot/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    15. Chain of Thought Reasoning
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../16_nlg/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    16. Nature Language Generation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../17_imp_nlg/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    17. Improving Generation and Training for NLG
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../18_eval_nlu/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    18. Evaluation of NLU Systems
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../19_eval_nlg/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    19. Evaluation of NLG Systems
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../20_post_training/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    20. Post-training
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../21_advanced_topics/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    21. Advanced Topics in Language Modelling
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    22. LLM Training Basics
    
  </span>
  

      </a>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../23_reasoning/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    23. Reasoning in LLMs
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../print_page/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Print/PDF
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
    <a href="https://github.com/SalK91/edit/main/docs/nlp/22_llm_training_basics.md" title="Edit this page" class="md-content__button md-icon" rel="edit">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"></path></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/SalK91/raw/main/docs/nlp/22_llm_training_basics.md" title="View source of this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"></path></svg>
    </a>
  


  <h1>22. LLM Training Basics</h1>

<h2 id="tensors-and-pytorch">Tensors and PyTorch<a class="headerlink" href="#tensors-and-pytorch" title="Permanent link">¶</a></h2>
<p>Tensors are the basic building block for storing everything in deep learning: parameters, gradients, optimizer state, data, and activations. Almost all of these are stored as floating-point numbers.</p>
<p>By default, tensors live in CPU memory. To leverage the massive parallelism of GPUs, we move them to GPU memory via <code>.to(device)</code> or <code>.cuda()</code>.</p>
<h3 id="what-is-a-tensor">What is a Tensor?<a class="headerlink" href="#what-is-a-tensor" title="Permanent link">¶</a></h3>
<p>PyTorch tensors are pointers into allocated memory, plus metadata describing:</p>
<ul>
<li><code>shape</code></li>
<li><code>stride</code> — how many elements to skip to move along each axis</li>
<li><code>dtype</code></li>
<li><code>device</code></li>
</ul>
<p>Most tensors are created from performing operations on other tensors. Each operation has some memory and compute consequence. Many operations simply provide a different <em>view</em> of the tensor. This does not make a copy, and therefore mutations in one tensor affect the other.</p>
<h3 id="optional-math-example">Optional math example<a class="headerlink" href="#optional-math-example" title="Permanent link">¶</a></h3>
<p>A tensor <span class="arithmatex">\(x \in \mathbb{R}^{m \times n}\)</span> is stored as a contiguous 1-D block of memory, with metadata describing how to interpret it. The stride vector <span class="arithmatex">\(s\)</span> defines indexing via:</p>
<p>
<script type="math/tex">
x[i, j] = \text{memory}[i \cdot s_0 + j \cdot s_1]
</script>
</p>
<p>If a view operation reshapes <span class="arithmatex">\(x\)</span> without copying, the underlying memory remains the same:</p>
<p>
<script type="math/tex">
x' = \text{view}(x), \quad \text{ptr}(x') = \text{ptr}(x)
</script>
</p>
<h2 id="flops-and-performance-in-deep-learning">FLOPs and Performance in Deep Learning<a class="headerlink" href="#flops-and-performance-in-deep-learning" title="Permanent link">¶</a></h2>
<p>A FLOP (floating-point operation) is a basic arithmetic operation (e.g., addition or multiplication) on floating-point numbers. It is a standard measure of computational work in deep learning.</p>
<h4 id="example-linear-layer-flops">Example: Linear Layer FLOPs<a class="headerlink" href="#example-linear-layer-flops" title="Permanent link">¶</a></h4>
<p>Suppose we apply a linear model to a batch of <span class="arithmatex">\(B\)</span> vectors of dimension <span class="arithmatex">\(D\)</span>, mapping to <span class="arithmatex">\(K\)</span> outputs:</p>
<div class="highlight"><pre><span></span><code><span class="n">B</span> <span class="o">=</span> <span class="mi">16384</span>  <span class="c1"># Batch size (e.g., number of tokens)</span>
<span class="n">D</span> <span class="o">=</span> <span class="mi">32768</span>  <span class="c1"># Input dimension</span>
<span class="n">K</span> <span class="o">=</span> <span class="mi">8192</span>   <span class="c1"># Output dimension</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">get_device</span><span class="p">()</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">@</span> <span class="n">w</span>
</code></pre></div>
<p>Each output <span class="arithmatex">\(y_{ik} = \sum_j x_{ij} w_{jk}\)</span> requires <span class="arithmatex">\(D\)</span> multiplications
and <span class="arithmatex">\(D - 1\)</span> additions.</p>
<p>Approximate total FLOPs:</p>
<div class="arithmatex">\[
FLOPs = 2  \times B  \times D  \times K
\]</div>
<h3 id="other-flops-estimates">Other FLOPs Estimates<a class="headerlink" href="#other-flops-estimates" title="Permanent link">¶</a></h3>
<ul>
<li>Elementwise operation (e.g., ReLU on <span class="arithmatex">\(m imes n\)</span> matrix): <span class="arithmatex">\(mn\)</span> FLOPs</li>
<li>Matrix addition (<span class="arithmatex">\(m \times n + m \times n\)</span>): <span class="arithmatex">\(mn\)</span> FLOPs</li>
<li>Normalization layers: <span class="arithmatex">\(O(mn)\)</span> FLOPs</li>
</ul>
<p>In general, matrix multiplications dominate FLOPs in large models like
Transformers.</p>
<h3 id="interpreting-flops-in-llms">Interpreting FLOPs in LLMs<a class="headerlink" href="#interpreting-flops-in-llms" title="Permanent link">¶</a></h3>
<ul>
<li><span class="arithmatex">\(B\)</span> is number of tokens or batch size</li>
<li><span class="arithmatex">\(D \times K\)</span> is number of parameters in a linear layer</li>
<li>Forward pass FLOPs: <span class="arithmatex">\(2 \cdot B \cdot D \cdot K\)</span></li>
<li>Total FLOPs: Sum over all layers, multiplied by batch size and sequence length</li>
</ul>
<h3 id="rule-of-thumb">Rule of thumb<a class="headerlink" href="#rule-of-thumb" title="Permanent link">¶</a></h3>
<div class="arithmatex">\[FLOPs \approx 2 \cdot    \text{#tokens} \cdot  \text{#parameters (per layer)}\]</div>
<h3 id="model-flops-utilization-mfu">Model FLOPs Utilization (MFU)<a class="headerlink" href="#model-flops-utilization-mfu" title="Permanent link">¶</a></h3>
<p>Definition:</p>
<div class="arithmatex">\[
MFU = \frac{\text{Actual FLOPs/sec}}{\text{Peak Theoretical FLOPs/sec}}
\]</div>
<p>MFU indicates how closely the training process approaches the maximum
compute capability of the hardware.</p>
<h4 id="why-mfu-is-not-always-1">Why MFU is not always 1<a class="headerlink" href="#why-mfu-is-not-always-1" title="Permanent link">¶</a></h4>
<ul>
<li>Non-matmul operations (activations, normalization, data movement)
    are often memory-bound</li>
<li>Kernel launch overhead from many small kernels</li>
<li>Memory bandwidth bottlenecks</li>
<li>Irregular workloads (uneven tensor sizes, short sequences)</li>
<li>Communication overhead in multi-GPU setups (sync, data transfer)</li>
</ul>
<h4 id="what-is-a-good-mfu">What is a good MFU?<a class="headerlink" href="#what-is-a-good-mfu" title="Permanent link">¶</a></h4>
<p>Typically:</p>
<div class="arithmatex">\[
MFU \ge 0.5   \text{ is considered good}
\]</div>
<p>MFU improves when:</p>
<ul>
<li>Matrix multiplications dominate the workload</li>
<li>Batch sizes and sequence lengths are large</li>
<li>Code is optimized for the hardware</li>
</ul>
<h2 id="mixed-precision-training">Mixed-Precision Training<a class="headerlink" href="#mixed-precision-training" title="Permanent link">¶</a></h2>
<h3 id="floating-point-formats-in-gpus">Floating-Point Formats in GPUs<a class="headerlink" href="#floating-point-formats-in-gpus" title="Permanent link">¶</a></h3>
<h4 id="floating-point-101">Floating-point 101<a class="headerlink" href="#floating-point-101" title="Permanent link">¶</a></h4>
<p>A binary floating-point number is encoded as:</p>
<div class="arithmatex">\[\underbrace{\text{sign}}_{\;1\;\text{bit}}\;
\underbrace{\text{exponent}}_{\;e\;\text{bits}}\;
\underbrace{\text{mantissa / significand}}_{\;m\;\text{bits}}
\]</div>
<table>
<thead>
<tr>
<th>Format</th>
<th style="text-align: right;">Bits</th>
<th style="text-align: right;">Exponent</th>
<th style="text-align: right;">Mantissa</th>
<th>Approx. Range</th>
</tr>
</thead>
<tbody>
<tr>
<td>FP32 (single)</td>
<td style="text-align: right;">32</td>
<td style="text-align: right;">8</td>
<td style="text-align: right;">23</td>
<td><span class="arithmatex">\(10^{-45}\)</span> – <span class="arithmatex">\(10^{38}\)</span></td>
</tr>
<tr>
<td>FP16 (half)</td>
<td style="text-align: right;">16</td>
<td style="text-align: right;">5</td>
<td style="text-align: right;">10</td>
<td><span class="arithmatex">\(2 \times 10^{-14}\)</span> – <span class="arithmatex">\(2 \times 10^{15}\)</span></td>
</tr>
</tbody>
</table>
<p>Precision vs. range: Reducing the mantissa increases spacing between representable values, so small increments (e.g. <span class="arithmatex">\(1.0001\)</span>) round to <span class="arithmatex">\(1.0\)</span> in FP16.<br>
A narrower exponent field also shrinks dynamic range, increasing overflow/underflow risk.</p>
<h3 id="fp32-vs-fp16-in-neural-network-training">FP32 vs. FP16 in Neural-Network Training<a class="headerlink" href="#fp32-vs-fp16-in-neural-network-training" title="Permanent link">¶</a></h3>
<ul>
<li>
<p>Default FP32 training: Parameters and gradients are stored in FP32. High memory usage <span class="arithmatex">\(\rightarrow\)</span> risk of OOM on large models.</p>
</li>
<li>
<p>Naïve FP16 swap: Reduces memory and bandwidth by 50%, but:</p>
<ul>
<li>Gradients may underflow to zero</li>
<li>Weight updates lose precision <span class="arithmatex">\(\rightarrow\)</span> poor convergence</li>
</ul>
</li>
</ul>
<h3 id="mixed-precision-training-core-idea">Mixed-Precision Training: Core Idea<a class="headerlink" href="#mixed-precision-training-core-idea" title="Permanent link">¶</a></h3>
<p>Keep critical operations in FP32 while using FP16 where safe:</p>
<ol>
<li>Maintain a set of FP32 master weights</li>
<li>Cast a working copy of the model to FP16; do the forward pass there.</li>
<li>Back-propagate (initial gradients in FP16)</li>
<li>Convert (copy) gradients to FP32</li>
<li>Update the FP32 master weights with your optimizer (SGD/Adam, etc.).</li>
<li>Cast the updated weights back to FP16 for the next forward pass.</li>
</ol>
<h3 id="preventing-gradient-underflow-dynamic-loss-scaling">Preventing Gradient Underflow: Dynamic Loss Scaling<a class="headerlink" href="#preventing-gradient-underflow-dynamic-loss-scaling" title="Permanent link">¶</a></h3>
<p>Even with mixed precision, tiny gradients can vanish. A practical recipe, adapted from:</p>
<p>Procedure:</p>
<ul>
<li>Choose a loss‑scaling factor <span class="arithmatex">\(S\)</span> (e.g.\ powers of two).\footnote{Modern frameworks adjust <span class="arithmatex">\(S\)</span> automatically (“dynamic” scaling).}</li>
<li>Multiply the computed loss by <span class="arithmatex">\(S\)</span> before back‑propagation.</li>
<li>Compute FP16 gradients of the scaled loss.</li>
<li>Convert gradients to FP32 and divide them by <span class="arithmatex">\(S\)</span>.</li>
<li>Proceed with the usual FP32 weight update \&amp; casting loop above.</li>
</ul>
<p><a class="glightbox" data-type="image" data-width="auto" data-height="auto" href="../images/mixedprecision.png" data-desc-position="bottom"><img alt="Pytorch - Mixed Precision Training" src="../images/mixedprecision.png"></a></p>
<h3 id="benefits">Benefits<a class="headerlink" href="#benefits" title="Permanent link">¶</a></h3>
<ul>
<li><span class="arithmatex">\(\approx 2\times\)</span> faster math on Tensor Cores (Volta/Ampere+)</li>
<li><span class="arithmatex">\(\approx 2\times\)</span> lower memory footprint, enabling larger batch sizes or models.</li>
<li>Same convergence as FP32 when loss scaling is correct</li>
</ul>
<h3 id="caveats">Caveats<a class="headerlink" href="#caveats" title="Permanent link">¶</a></h3>
<ul>
<li>Verify numerical stability on your model; some niche layers (e.g. custom CUDA kernels) may not be FP16‑safe.</li>
<li>Loss scaling adds minor overhead if done manually; use the built‑in API of your deep‑learning framework whenever possible.</li>
</ul>
<h2 id="bfloat16">BFloat16<a class="headerlink" href="#bfloat16" title="Permanent link">¶</a></h2>
<p>Google Brain developed bfloat (brain floating point) in 2018 to address this issue. bfloat16 uses the same memory as float16 but has the same dynamic range as float32! The only catch is that the resolution is worse, but this matters less for deep learning.</p>
<p>Core idea: BFloat16 (16-bit float) keeps the same exponent size as FP32, so it has a very wide range but with lower precision (7 mantissa bits).  </p>
<p>This makes it:</p>
<ul>
<li>Fast and memory-efficient like FP16</li>
<li>Avoids gradient underflow</li>
<li>No loss scaling required</li>
</ul>
<h4 id="implementation-steps">Implementation steps<a class="headerlink" href="#implementation-steps" title="Permanent link">¶</a></h4>
<ol>
<li>Keep a set og FP32 master weights</li>
<li>Cast model to BFloat16 for forward/backward passes(<code>model.to(torch.bfloat16)</code>)</li>
<li>Gradients accumulate in FP32 by default</li>
<li>Update FP32 master weights as usual</li>
<li>Cast updated weights back to BFloat16 for next step</li>
</ol>
<p>No loss scaling required, BFloat16 simplifies mixed-precision training by providing FP32-like range with FP16-like speed and memory savings.</p>
<h2 id="multi-gpu-training-from-ddp-to-zero">Multi-GPU Training: From DDP to ZeRO<a class="headerlink" href="#multi-gpu-training-from-ddp-to-zero" title="Permanent link">¶</a></h2>
<ol>
<li>
<p>Single-GPU Setup: In a typical mixed-precision setup:</p>
<ul>
<li>Model parameters: Stored in FP16 on GPU VRAM.</li>
<li>Optimizer state (FP32):<ul>
<li>Master weights (for precision-preserving updates)</li>
<li>Momentum buffers (e.g., Adam)</li>
<li>Variance estimates (e.g., Adam)</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Distributed Data Parallel (DDP) — Baseline: DDP replicates the entire model and optimizer state across all GPUs and splits the input data:</p>
<ul>
<li>
<p>Each GPU computes a forward and backward pass on its mini-batch.</p>
</li>
<li>
<p>During backpropagation, gradients are synchronized across all GPUs using an AllReduce.</p>
</li>
<li>
<p>Each GPU independently applies the optimizer update to its local copy of the model.</p>
</li>
</ul>
</li>
</ol>
<p>Communication cost: Each gradient (typically in FP32 unless cast to FP16) is sent across GPUs. The bandwidth cost is roughly ∼4 bytes per parameter (or ∼2 bytes with
FP16 compression)</p>
<p>Limitation: Memory overhead scales poorly — each GPU stores a full copy of model parameters and optimizer state.</p>
<h2 id="zero-zero-redundancy-optimizer-deepspeed">ZeRO: Zero Redundancy Optimizer (DeepSpeed)<a class="headerlink" href="#zero-zero-redundancy-optimizer-deepspeed" title="Permanent link">¶</a></h2>
<p>ZeRO removes the major inefficiency of Distributed Data Parallel (DDP), where every GPU keeps a full copy of model parameters, gradients, and optimizer states. Instead, ZeRO partitions (shards) training states across GPUs so that each device holds only the slice of memory it actually needs, while still participating in full model training.</p>
<h3 id="zero-stage-1-optimizer-state-sharding">ZeRO Stage-1: Optimizer State Sharding<a class="headerlink" href="#zero-stage-1-optimizer-state-sharding" title="Permanent link">¶</a></h3>
<ul>
<li>Each GPU stores:<ul>
<li>The full FP16 model</li>
<li>Only a shard of the optimizer state</li>
</ul>
</li>
<li>Each GPU computes gradients on its data shard</li>
<li>Gradients are reduce-scattered so each GPU receives only the gradients for its parameter shard</li>
<li>Each GPU updates its own optimizer shard and corresponding parameters</li>
<li>Updated parameters are all-gathered so all GPUs hold a synchronized model</li>
</ul>
<h3 id="zero-stage-2-optimizer-state-gradient-sharding">ZeRO Stage-2: Optimizer State + Gradient Sharding<a class="headerlink" href="#zero-stage-2-optimizer-state-gradient-sharding" title="Permanent link">¶</a></h3>
<p>Builds upon Stage-1 by also sharding gradients:</p>
<ul>
<li>Gradients are never fully instantiated in memory</li>
<li>During backward pass:<ul>
<li>Each GPU computes gradients for a layer</li>
<li>Immediately reduces gradients to the GPU responsible for that parameter shard</li>
<li>Frees local gradient memory once sent</li>
</ul>
</li>
<li>After backpropagation, each GPU:<ul>
<li>Updates its optimizer and parameter shards locally</li>
<li>Parameters are synchronized via all-gather before the next forward pass</li>
</ul>
</li>
</ul>
<p>Benefit: significantly reduces memory footprint — gradients and optimizer states are distributed.</p>
<h2 id="zero-stage-3-full-model-gradient-and-optimizer-sharding">ZeRO Stage-3: Full Model, Gradient, and Optimizer Sharding<a class="headerlink" href="#zero-stage-3-full-model-gradient-and-optimizer-sharding" title="Permanent link">¶</a></h2>
<p>In this final stage:</p>
<ul>
<li>Model parameters are sharded across GPUs — no GPU stores the full model</li>
<li>Parameters are materialized just-in-time during forward/backward and deallocated afterward</li>
<li>Training requires orchestration of:<ul>
<li>Parameter gathering</li>
<li>Gradient sharding and reduction</li>
<li>Activation checkpointing (optional but common)</li>
</ul>
</li>
<li>Implemented in PyTorch via <code>torch.distributed.fsdp</code> (Fully Sharded Data Parallel)</li>
</ul>
<p>Use case: enables training of models with hundreds of billions to trillions of parameters on commodity GPU clusters.</p>
<table>
<thead>
<tr>
<th>Training Strategy</th>
<th>Model Sharded</th>
<th>Gradients Sharded</th>
<th>Optimizer Sharded</th>
</tr>
</thead>
<tbody>
<tr>
<td>DDP (Baseline)</td>
<td><span class="arithmatex">\(\times\)</span></td>
<td><span class="arithmatex">\(\times\)</span></td>
<td><span class="arithmatex">\(\times\)</span></td>
</tr>
<tr>
<td>ZeRO Stage-1</td>
<td><span class="arithmatex">\(\times\)</span></td>
<td><span class="arithmatex">\(\times\)</span></td>
<td><span class="arithmatex">\(\checkmark\)</span></td>
</tr>
<tr>
<td>ZeRO Stage-2</td>
<td><span class="arithmatex">\(\times\)</span></td>
<td><span class="arithmatex">\(\checkmark\)</span></td>
<td><span class="arithmatex">\(\checkmark\)</span></td>
</tr>
<tr>
<td>ZeRO Stage-3</td>
<td><span class="arithmatex">\(\checkmark\)</span></td>
<td><span class="arithmatex">\(\checkmark\)</span></td>
<td><span class="arithmatex">\(\checkmark\)</span></td>
</tr>
</tbody>
</table>
<h2 id="key-takeaways">Key Takeaways<a class="headerlink" href="#key-takeaways" title="Permanent link">¶</a></h2>
<ul>
<li>ZeRO reduces memory consumption linearly with GPU count.</li>
<li>Enables training of large models without sacrificing batch size or needing model parallelism.</li>
<li>Fully Sharded Data Parallel (FSDP) in PyTorch and DeepSpeed provide user-friendly APIs to leverage ZeRO at scale.</li>
</ul>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"></path></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer">
        
          
          <a href="../21_advanced_topics/" class="md-footer__link md-footer__link--prev" aria-label="Previous: 21. Advanced Topics in Language Modelling">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                21. Advanced Topics in Language Modelling
              </div>
            </div>
          </a>
        
        
          
          <a href="../23_reasoning/" class="md-footer__link md-footer__link--next" aria-label="Next: 23. Reasoning in LLMs">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                23. Reasoning in LLMs
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"></path></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      © 2025 Salman Khan — Educational Use Only
    </div>
  
  
</div>
      
        
<div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/SalK91/reinforcement_learning" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"></path></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.tabs", "navigation.sections", "navigation.expand", "navigation.indexes", "navigation.path", "navigation.top", "navigation.footer", "toc.follow", "content.code.copy", "content.action.edit", "content.action.view", "search.suggest", "search.highlight"], "search": "../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
        <script src="../../js/print-site.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
      
    
  
<script id="init-glightbox">const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(()=>{ lightbox.reload(); });
</script></body></html>