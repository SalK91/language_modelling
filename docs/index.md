# Lectures on Language Modelling
Welcome to *Lectures on RLanguage Modelling*, a structured set of lecture notes designed to build the mathematical foundations required to understand, analyze, and develop modern language models.

These notes are inspired by and draw heavily on material from:

- Stanford CS224N: NLP with Deep Learning (Spring 2024)
- Stanford CME295: Transformers & LLMs (Autumn 2025) 

The goal is not to reproduce these courses, but to synthesize their core ideas into a coherent, optimization and mathematics first perspective suitable for practitioners and researchers.


## Resume from:


https://cs329a.stanford.edu/
https://cseweb.ucsd.edu/~yiying/cse291a-fall25/reading/
https://rdi.berkeley.edu/agentic-ai/f25


1. ML Systems Seminars - Stanford
2. ML with Graphs - Stanford CS224W
3. Stanford CS25 - Transformers United
4. Standford CS336 Language modelling from scratch
5. Distributed Systems MIT 6.824
6. Stanford CS224U
7. Theory of Statistical Machine Learning:
    https://www.youtube.com/playlist?list=PLwUOK5j_XOsdfVAGKErx9HqnrVZIuRbZ2

8. 6.041 Probabilistic Systems Analysis and Applied Probability

10. Python Advanced Tutorials
    https://www.youtube.com/watch?v=KSiRzuSx120&list=PL7yh-TELLS1FuqLSjl5bgiQIEH25VEmIc


11. MIT 18.642 Topics in Mathematics with Applications in Finance, Fall 2024