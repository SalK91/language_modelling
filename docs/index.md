# Lectures on Language Modelling
Welcome to *Lectures on RLanguage Modelling*, a structured set of lecture notes designed to build the mathematical foundations required to understand, analyze, and develop modern language models.

These notes are inspired by and draw heavily on material from:

- Stanford CS224N: NLP with Deep Learning (Spring 2024)
- Stanford CME295: Transformers & LLMs (Autumn 2025) 

The goal is not to reproduce these courses, but to synthesize their core ideas into a coherent, optimization and mathematics first perspective suitable for practitioners and researchers.





## Resume from:

https://cme295.stanford.edu/syllabus/


https://www.youtube.com/watch?v=VlA_jt_3Qc4


https://cs329a.stanford.edu/
https://cseweb.ucsd.edu/~yiying/cse291a-fall25/reading/
https://rdi.berkeley.edu/agentic-ai/f25