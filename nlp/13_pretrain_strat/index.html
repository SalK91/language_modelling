<!DOCTYPE html><html lang="en" class="no-js"><head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Structured lecture notes on Natural Language Processing.">
      
      
        <meta name="author" content="Salman Khan">
      
      
        <link rel="canonical" href="https://salk91.github.io/language_modelling/nlp/13_pretrain_strat/">
      
      
        <link rel="prev" href="../12_pretraining/">
      
      
        <link rel="next" href="../14_finetuning/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.20">
    
    
      
        <title>13. Pre-training Strategies - NLP Lecture Notes</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.e53b48f4.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Merriweather:300,300i,400,400i,700,700i%7CFira+Code:400,400i,700,700i&amp;display=fallback">
        <style>:root{--md-text-font:"Merriweather";--md-code-font:"Fira Code"}</style>
      
    
    
      <link rel="stylesheet" href="../../css/print-site.css">
    
      <link rel="stylesheet" href="../../css/print-site-material.css">
    
      <link rel="stylesheet" href="../../styles/extra.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  <link href="../../assets/stylesheets/glightbox.min.css" rel="stylesheet"><script src="../../assets/javascripts/glightbox.min.js"></script><style id="glightbox-style">
            html.glightbox-open { overflow: initial; height: 100%; }
            .gslide-title { margin-top: 0px; user-select: text; }
            .gslide-desc { color: #666; user-select: text; }
            .gslide-image img { background: white; }
            .gscrollbar-fixer { padding-right: 15px; }
            .gdesc-inner { font-size: 0.75rem; }
            body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color); }
            body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color); }
            body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color); }
        </style></head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="cyan">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#13-the-pretraining-strategies" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="NLP Lecture Notes" class="md-header__button md-logo" aria-label="NLP Lecture Notes" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"></path></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"></path></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            NLP Lecture Notes
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              13. Pre-training Strategies
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="cyan" aria-label="Switch to dark mode" type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"></path></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="cyan" aria-label="Switch to light mode" type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m3.55 19.09 1.41 1.41 1.8-1.79-1.42-1.42M12 6c-3.31 0-6 2.69-6 6s2.69 6 6 6 6-2.69 6-6c0-3.32-2.69-6-6-6m8 7h3v-2h-3m-2.76 7.71 1.8 1.79 1.41-1.41-1.79-1.8M20.45 5l-1.41-1.4-1.8 1.79 1.42 1.42M13 1h-2v3h2M6.76 5.39 4.96 3.6 3.55 5l1.79 1.81zM1 13h3v-2H1m12 9h-2v3h2"></path></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/SalK91/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"></path></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../1_intro/" class="md-tabs__link">
          
  
  
    
  
  Natural Language Processing

        </a>
      </li>
    
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../print_page/" class="md-tabs__link">
        
  
  
    
  
  Print/PDF

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="NLP Lecture Notes" class="md-nav__button md-logo" aria-label="NLP Lecture Notes" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"></path></svg>

    </a>
    NLP Lecture Notes
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/SalK91/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"></path></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Natural Language Processing
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Natural Language Processing
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1_intro/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    1. NLP an introduction
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2_lmnp/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2. Language Models and Word Sequence Probability
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../3_nn/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3. Window-based Neural Language Models
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../4_rnn/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    4. Recurrent Neural Networks
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../5_lstm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    5. Long Short-Term Memory (LSTM) Networks
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../6_app_rnn/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    6. Applications of RNN
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../7_eval_nlp/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    7. Evaluation of Language Models
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../8_attention_seq2seq/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    8. Attention Mechanism in Sequence-to-Sequence Models
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../9_selfattention/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    9. Self- Attention
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../10_archi/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    10. Transformer Architectures
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../11_tokens/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    11. Tokenization
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../12_pretraining/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    12. Pre-training
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    13. Pre-training Strategies
    
  </span>
  

      </a>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../14_finetuning/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    14. Fine-tuning
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../15_cot/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    15. Chain of Thought Reasoning
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../16_nlg/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    16. Nature Language Generation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../17_imp_nlg/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    17. Improving Generation and Training for NLG
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../18_eval_nlu/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    18. Evaluation of NLU Systems
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../19_eval_nlg/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    19. Evaluation of NLG Systems
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../20_post_training/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    20. Post-training
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../21_advanced_topics/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    21. Advanced Topics in Language Modelling
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../22_llm_training_basics/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    22. LLM Training Basics
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../23_reasoning/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    23. Reasoning in LLMs
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../print_page/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Print/PDF
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
    <a href="https://github.com/SalK91/edit/main/docs/nlp/13_pretrain_strat.md" title="Edit this page" class="md-content__button md-icon" rel="edit">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"></path></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/SalK91/raw/main/docs/nlp/13_pretrain_strat.md" title="View source of this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"></path></svg>
    </a>
  


<h1 id="13-the-pretraining-strategies">13. The Pretraining Strategies<a class="headerlink" href="#13-the-pretraining-strategies" title="Permanent link">¶</a></h1>
<p>This section describes how pretraining objectives differ across encoder, decoder, and encoder–decoder architectures, and why these differences matter.</p>
<p>The pretraining/fine-tuning paradigm has become the dominant approach in modern NLP. Instead of training models from scratch for every task, we first train a general-purpose language model on a large, unlabeled corpus, and then adapt it to a specific task using a smaller labeled dataset. This approach enables models to transfer general linguistic knowledge learned during pretraining into a wide variety of downstream applications.</p>
<ul>
<li>Step 1: Pretraining — Train on a large-scale unsupervised objective such as language modeling. The model learns broad statistical regularities, syntax, semantics, and even some world knowledge from raw text</li>
<li>Step 2: Fine-tuning — Adapt the pretrained model to a specific supervised task (e.g., sentiment classification, question answering, named entity recognition) using a smaller, labeled dataset</li>
</ul>
<p><a class="glightbox" data-type="image" data-width="auto" data-height="auto" href="../images/pre_vs_fine.png" data-desc-position="bottom"><img alt="Pretraining and Fine Tuning" src="../images/pre_vs_fine.png"></a></p>
<p>These two stages decouple language understanding from task-specific supervision. This two-stage procedure has been remarkably effective, especially when labeled data is scarce, as the pretrained model already encodes a strong inductive bias about language.</p>
<h2 id="why-does-this-work-an-optimization-view">Why Does This Work? An Optimization View<a class="headerlink" href="#why-does-this-work-an-optimization-view" title="Permanent link">¶</a></h2>
<p>From the perspective of training neural networks with stochastic gradient descent, pretraining provides a highly informative initialization for model parameters.</p>
<p>Let <span class="arithmatex">\(\mathcal{L}_{\text{pretrain}}(\theta)\)</span> denote the pretraining loss, and let <span class="arithmatex">\(\hat{\theta}\)</span> be the parameters obtained by minimizing this loss:</p>
<div class="arithmatex">\[
\hat{\theta} \approx \arg\min_\theta \mathcal{L}_{\text{pretrain}}(\theta)
\]</div>
<p>During fine-tuning, we optimize a new task-specific loss <span class="arithmatex">\(\mathcal{L}_{\text{finetune}}(\theta)\)</span>, starting from the pretrained parameters:</p>
<div class="arithmatex">\[
\theta^* = \arg\min_\theta \mathcal{L}_{\text{finetune}}(\theta),
\quad \text{initialized at } \theta = \hat{\theta}
\]</div>
<p>This setup offers two complementary advantages:</p>
<ol>
<li>
<p>Good starting point:  The pretrained parameters <span class="arithmatex">\(\hat{\theta}\)</span> already encode general linguistic knowledge, meaning that gradient-based optimization during fine-tuning is more likely to converge quickly and to a good local minimum</p>
</li>
<li>
<p>Better generalization: Due to the geometry of the loss landscape, stochastic gradient descent tends to stay relatively close to <span class="arithmatex">\(\hat{\theta}\)</span>. If the local minima around <span class="arithmatex">\(\hat{\theta}\)</span> are well-aligned with generalization, then the fine-tuned model is more likely to perform well on unseen data</p>
</li>
</ol>
<h2 id="intuition-behind-gradient-propagation">Intuition Behind Gradient Propagation<a class="headerlink" href="#intuition-behind-gradient-propagation" title="Permanent link">¶</a></h2>
<p>Another benefit is that the gradients of the fine-tuning loss <span class="arithmatex">\(\nabla \mathcal{L}_{\text{finetune}}(\theta)\)</span> often propagate more effectively when <span class="arithmatex">\(\theta\)</span> is initialized at <span class="arithmatex">\(\hat{\theta}\)</span>. Pretraining shapes the model’s representations such that downstream gradients flow through semantically meaningful feature spaces, improving both optimization stability and sample efficiency.</p>
<h2 id="summary">Summary<a class="headerlink" href="#summary" title="Permanent link">¶</a></h2>
<p>The pretraining/fine-tuning paradigm represents a powerful instantiation of transfer learning in NLP. It leverages large-scale unsupervised data to produce models with rich linguistic priors and uses supervised fine-tuning to tailor those priors to task-specific objectives. From both empirical and theoretical perspectives, this strategy enables better generalization, faster convergence, and higher performance across nearly all areas of natural language understanding and generation.</p>
<h2 id="pretraining-encoder-architectures">Pretraining Encoder Architectures<a class="headerlink" href="#pretraining-encoder-architectures" title="Permanent link">¶</a></h2>
<p>Transformer-based encoder models, particularly those following the BERT architecture, are pretrained using objectives that leverage the bidirectional nature of attention. Unlike autoregressive language models, which condition only on past tokens, encoder architectures benefit from full left-and-right context, enabling richer and more globally informed token representations.</p>
<h2 id="masked-language-modeling-mlm">Masked Language Modeling (MLM)<a class="headerlink" href="#masked-language-modeling-mlm" title="Permanent link">¶</a></h2>
<p>The core idea behind encoder pretraining is the masked language modeling objective. In this setup, a fraction of the input tokens is replaced with a special <code>[MASK]</code> token. The model is then trained to predict the original tokens at these masked positions, conditioning on the surrounding unmasked context. Formally, given an input sequence  <span class="arithmatex">\(x = (w_1, w_2, \dots, w_T)\)</span><br>
and its corrupted version <span class="arithmatex">\(\tilde{x}\)</span>, the model learns parameters <span class="arithmatex">\(\theta\)</span> that maximize the likelihood <span class="arithmatex">\(p_\theta(x \mid \tilde{x})\)</span>.</p>
<div class="arithmatex">\[
\mathbf{h}_1, \dots, \mathbf{h}_T = \text{Encoder}(w_1, \dots, w_T)
\]</div>
<div class="arithmatex">\[
\hat{y}_i \sim \text{softmax}(A \mathbf{h}_i + b),
\quad \text{for masked positions } i
\]</div>
<p>where <span class="arithmatex">\(A\)</span> and <span class="arithmatex">\(b\)</span> are learned projection parameters.</p>
<p>The BERT pretraining procedure masks 15% of tokens according to the following strategy:</p>
<ul>
<li>80% of the time, the token is replaced with <code>[MASK]</code></li>
<li>10% of the time, it is replaced with a random token</li>
<li>10% of the time, it is left unchanged but still predicted</li>
</ul>
<p>This scheme prevents the model from overfitting to the presence of <code>[MASK]</code> tokens and encourages robust representations even for unmasked inputs.</p>
<h2 id="next-sentence-prediction-nsp">Next Sentence Prediction (NSP)<a class="headerlink" href="#next-sentence-prediction-nsp" title="Permanent link">¶</a></h2>
<p>In addition to masked language modeling, BERT was originally trained with a binary classification task known as next sentence prediction. Given two input segments, the model predicts whether the second segment follows the first in the original corpus or was randomly sampled. Subsequent studies such as RoBERTa showed that removing NSP can improve downstream performance, suggesting that NSP is not essential.</p>
<h2 id="advancements-and-variants">Advancements and Variants<a class="headerlink" href="#advancements-and-variants" title="Permanent link">¶</a></h2>
<p>Numerous refinements to the BERT pretraining methodology have been proposed:</p>
<ul>
<li>
<p>RoBERTa:   Trains longer, on more data, removes NSP, uses dynamic masking and larger batch sizes</p>
</li>
<li>
<p>SpanBERT:  Masks contiguous spans of tokens instead of individual ones, promoting span-level representations</p>
</li>
</ul>
<h2 id="limitations-of-encoder-only-pretraining">Limitations of Encoder-Only Pretraining<a class="headerlink" href="#limitations-of-encoder-only-pretraining" title="Permanent link">¶</a></h2>
<p>While encoder models like BERT excel at understanding and classification tasks (e.g., sentiment analysis, QA), they are not directly suited for sequence generation due to their non-autoregressive architecture. For tasks requiring fluent text generation (e.g., summarization, translation), decoder-based or encoder-decoder models are more appropriate. Nonetheless, pretrained encoders remain foundational across a wide array of NLP applications due to their strong contextual representations and adaptability to fine-tuning for downstream tasks.</p>
<h2 id="pretraining-encoderdecoder-architectures">Pretraining Encoder–Decoder Architectures<a class="headerlink" href="#pretraining-encoderdecoder-architectures" title="Permanent link">¶</a></h2>
<p>Encoder–decoder models combine the strengths of both architectures: the encoder produces rich, bidirectional representations of input sequences, while the decoder performs autoregressive generation conditioned on these representations. This architecture is particularly well-suited for sequence-to-sequence tasks such as machine translation, summarization, and question answering.</p>
<h2 id="why-use-encoderdecoder-models">Why Use Encoder–Decoder Models?<a class="headerlink" href="#why-use-encoderdecoder-models" title="Permanent link">¶</a></h2>
<ul>
<li>Encoders build contextual representations using bidirectional attention</li>
<li>Decoders enable autoregressive generation conditioned on encoded input and past outputs</li>
<li>Encoder–decoder models enable powerful conditional generation while leveraging deep understanding of the input.</li>
</ul>
<h2 id="pretraining-strategy-language-modeling-with-encoders">Pretraining Strategy: Language Modeling with Encoders<a class="headerlink" href="#pretraining-strategy-language-modeling-with-encoders" title="Permanent link">¶</a></h2>
<p>A naive extension of language modeling to encoder–decoder architectures splits the input sequence:</p>
<ul>
<li>A prefix of the input (e.g., tokens <span class="arithmatex">\(w_1, \dots, w_T\)</span>) is passed to the encoder.</li>
<li>The decoder autoregressively generates the continuation</li>
</ul>
<div class="arithmatex">\[
\mathbf{h}_{1:T} = \text{Encoder}(w_{1:T}), \quad
\mathbf{h}_{T+1:T'} = \text{Decoder}(w_{1:T'}, \mathbf{h}_{1:T})
\]</div>
<div class="arithmatex">\[
P(y_i) \sim \text{softmax}(\mathbf{A}\mathbf{h}_i + \mathbf{b}), \quad i &gt; T
\]</div>
<p>This allows the encoder to learn bidirectional features while enabling the decoder to condition on them during generation. However, more specialized objectives have shown better performance.</p>
<h2 id="span-corruption-the-t5-objective">Span Corruption: The T5 Objective<a class="headerlink" href="#span-corruption-the-t5-objective" title="Permanent link">¶</a></h2>
<p>Span corruption is the core pretraining objective of the T5 model. Random spans of text are removed from the input and replaced with unique sentinel tokens such as <code>&lt;extra_id_0&gt;</code>. The decoder is trained to reconstruct the missing spans.</p>
<ul>
<li>Random spans of text are removed from the input</li>
<li>Each removed span is replaced with a unique sentinel token (e.g., <code>&lt;extra_id_0&gt;</code>).</li>
<li>The model is trained to reconstruct the missing spans from these placeholders.</li>
</ul>
<p><a class="glightbox" data-type="image" data-width="auto" data-height="auto" href="../images/span_corruption.png" data-desc-position="bottom"><img alt="Span Corruption" src="../images/span_corruption.png"></a></p>
<p>Example:</p>
<ul>
<li>Input: <code>The quick &lt;extra_id_0&gt; fox jumps &lt;extra_id_1&gt; the lazy dog.</code></li>
<li>Target: <code>&lt;extra_id_0&gt; brown &lt;extra_id_1&gt; over &lt;extra_id_2&gt;</code></li>
</ul>
<p>Advantages:</p>
<ul>
<li>The encoder benefits from full bidirectional context (unlike standard causal models).</li>
<li>The decoder is trained autoregressively, generating spans conditioned on encoder output.</li>
<li>The objective is implemented via input preprocessing; the model learns a language modeling task at the decoder side.</li>
</ul>
<h2 id="summary_1">Summary<a class="headerlink" href="#summary_1" title="Permanent link">¶</a></h2>
<p>Encoder–decoder pretraining balances bidirectional representation learning (via the encoder) with generative capability (via the decoder). Span corruption, as implemented in T5, has emerged as a highly effective strategy. It produces models that generalize well across a wide range of NLP tasks and are compatible with the "text-to-text" paradigm.</p>
<h2 id="pretraining-decoder-architectures">Pretraining Decoder Architectures<a class="headerlink" href="#pretraining-decoder-architectures" title="Permanent link">¶</a></h2>
<p>Decoder-only language models have emerged as a central architecture in modern NLP, particularly for tasks involving natural language generation. These models are pretrained autoregressively to maximize the likelihood of the next token conditioned on previous tokens:</p>
<div class="arithmatex">\[
p_\theta(w_t \mid w_{1:t-1})
\]</div>
<p>typically using causal (left-to-right) self-attention to ensure that each token only attends to its left context. This setup enables decoders to learn rich, context-sensitive representations suitable for both generation and classification tasks.</p>
<p><a class="glightbox" data-type="image" data-width="auto" data-height="auto" href="../images/decoder_pre.png" data-desc-position="bottom"><img alt="Decoder Pretraining" src="../images/decoder_pre.png"></a></p>
<h2 id="representation-learning-for-classification">Representation Learning for Classification<a class="headerlink" href="#representation-learning-for-classification" title="Permanent link">¶</a></h2>
<p>Despite being trained for generation, pretrained decoders can be repurposed for classification tasks by leveraging their hidden representations. A common approach is to use the final token's hidden state <span class="arithmatex">\(h_T\)</span> as a summary of the sequence and apply a linear classifier on top:</p>
<div class="arithmatex">\[
h_1, \dots, h_T = \text{Decoder}(w_1, \dots, w_T)
\]</div>
<div class="arithmatex">\[
y \sim \text{softmax}(A h_T + b)
\]</div>
<p>where <span class="arithmatex">\(A\)</span> and <span class="arithmatex">\(b\)</span> are task-specific parameters initialized randomly and optimized during finetuning. Importantly, gradients are backpropagated through the entire decoder, enabling the model to adapt its internal representations to the downstream task.</p>
<h2 id="sequence-generation-via-pretrained-decoders">Sequence Generation via Pretrained Decoders<a class="headerlink" href="#sequence-generation-via-pretrained-decoders" title="Permanent link">¶</a></h2>
<p>In generation settings, decoder models are used directly in the autoregressive manner in which they were pretrained. At each timestep, the decoder produces a distribution over the next token given the previously generated tokens:</p>
<div class="arithmatex">\[
h_1, \dots, h_{t-1} = \text{Decoder}(w_1, \dots, w_{t-1})
\]</div>
<div class="arithmatex">\[
w_t \sim \text{softmax}(A h_{t-1} + b)
\]</div>
<p>Here, <span class="arithmatex">\(A\)</span> and <span class="arithmatex">\(b\)</span> represent the output projection matrix and bias that were learned during pretraining. In many applications, these parameters are reused without modification; however, they may also be further finetuned alongside the decoder, depending on the task and data availability.</p>
<p>This generation paradigm is particularly effective for tasks such as:</p>
<ul>
<li>Dialogue modeling: where the decoder generates a response conditioned on the prior dialogue history.</li>
<li>Summarization: where the decoder generates a summary conditioned on a document input.</li>
</ul>
<h2 id="architectural-context-and-transferability">Architectural Context and Transferability<a class="headerlink" href="#architectural-context-and-transferability" title="Permanent link">¶</a></h2>
<p>Decoder-only models differ from encoder-decoder architectures (e.g., T5) in that they do not encode the input with a separate encoder. Instead, all information is processed through the decoder itself. This simplicity enables direct reuse of the pretrained decoder for diverse tasks with minimal architectural modification.</p>
<p>Pretraining provides:</p>
<ul>
<li>Transferability: Learned representations encode rich syntactic, semantic, and factual knowledge that generalize well across tasks.</li>
<li>Architectural reuse: The same pretrained model can support both classification and generation, reducing deployment complexity.</li>
<li>Scalability: Autoregressive training benefits from large-scale data and scales effectively with model size.</li>
</ul>
<p>Pretrained decoder architectures, as used in models such as GPT-2, GPT-3, and LLaMA, have demonstrated remarkable performance across a wide range of NLP benchmarks, confirming the utility of this simple yet powerful design.</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"></path></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer">
        
          
          <a href="../12_pretraining/" class="md-footer__link md-footer__link--prev" aria-label="Previous: 12. Pre-training">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                12. Pre-training
              </div>
            </div>
          </a>
        
        
          
          <a href="../14_finetuning/" class="md-footer__link md-footer__link--next" aria-label="Next: 14. Fine-tuning">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                14. Fine-tuning
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"></path></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      © 2025 Salman Khan — Educational Use Only
    </div>
  
  
</div>
      
        
<div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/SalK91/reinforcement_learning" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"></path></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.tabs", "navigation.sections", "navigation.expand", "navigation.indexes", "navigation.path", "navigation.top", "navigation.footer", "toc.follow", "content.code.copy", "content.action.edit", "content.action.view", "search.suggest", "search.highlight"], "search": "../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
        <script src="../../js/print-site.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
      
    
  
<script id="init-glightbox">const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(()=>{ lightbox.reload(); });
</script></body></html>