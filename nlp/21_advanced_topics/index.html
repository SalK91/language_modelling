<!DOCTYPE html><html lang="en" class="no-js"><head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Structured lecture notes on Natural Language Processing.">
      
      
        <meta name="author" content="Salman Khan">
      
      
        <link rel="canonical" href="https://salk91.github.io/language_modelling/nlp/21_advanced_topics/">
      
      
        <link rel="prev" href="../20_post_training/">
      
      
        <link rel="next" href="../22_llm_training_basics/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.20">
    
    
      
        <title>21. Advanced Topics in Language Modelling - NLP Lecture Notes</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.e53b48f4.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Merriweather:300,300i,400,400i,700,700i%7CFira+Code:400,400i,700,700i&amp;display=fallback">
        <style>:root{--md-text-font:"Merriweather";--md-code-font:"Fira Code"}</style>
      
    
    
      <link rel="stylesheet" href="../../css/print-site.css">
    
      <link rel="stylesheet" href="../../css/print-site-material.css">
    
      <link rel="stylesheet" href="../../styles/extra.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  <link href="../../assets/stylesheets/glightbox.min.css" rel="stylesheet"><script src="../../assets/javascripts/glightbox.min.js"></script><style id="glightbox-style">
            html.glightbox-open { overflow: initial; height: 100%; }
            .gslide-title { margin-top: 0px; user-select: text; }
            .gslide-desc { color: #666; user-select: text; }
            .gslide-image img { background: white; }
            .gscrollbar-fixer { padding-right: 15px; }
            .gdesc-inner { font-size: 0.75rem; }
            body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color); }
            body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color); }
            body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color); }
        </style></head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="cyan">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#advanced-topics-in-language-modelling" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="NLP Lecture Notes" class="md-header__button md-logo" aria-label="NLP Lecture Notes" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"></path></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"></path></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            NLP Lecture Notes
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              21. Advanced Topics in Language Modelling
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="cyan" aria-label="Switch to dark mode" type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"></path></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="cyan" aria-label="Switch to light mode" type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m3.55 19.09 1.41 1.41 1.8-1.79-1.42-1.42M12 6c-3.31 0-6 2.69-6 6s2.69 6 6 6 6-2.69 6-6c0-3.32-2.69-6-6-6m8 7h3v-2h-3m-2.76 7.71 1.8 1.79 1.41-1.41-1.79-1.8M20.45 5l-1.41-1.4-1.8 1.79 1.42 1.42M13 1h-2v3h2M6.76 5.39 4.96 3.6 3.55 5l1.79 1.81zM1 13h3v-2H1m12 9h-2v3h2"></path></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/SalK91/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"></path></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../1_intro/" class="md-tabs__link">
          
  
  
    
  
  Natural Language Processing

        </a>
      </li>
    
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../print_page/" class="md-tabs__link">
        
  
  
    
  
  Print/PDF

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="NLP Lecture Notes" class="md-nav__button md-logo" aria-label="NLP Lecture Notes" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"></path></svg>

    </a>
    NLP Lecture Notes
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/SalK91/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"></path></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Natural Language Processing
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Natural Language Processing
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1_intro/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    1. NLP an introduction
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2_lmnp/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2. Language Models and Word Sequence Probability
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../3_nn/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3. Window-based Neural Language Models
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../4_rnn/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    4. Recurrent Neural Networks
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../5_lstm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    5. Long Short-Term Memory (LSTM) Networks
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../6_app_rnn/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    6. Applications of RNN
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../7_eval_nlp/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    7. Evaluation of Language Models
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../8_attention_seq2seq/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    8. Attention Mechanism in Sequence-to-Sequence Models
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../9_selfattention/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    9. Self- Attention
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../10_archi/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    10. Transformer Architectures
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../11_tokens/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    11. Tokenization
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../12_pretraining/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    12. Pre-training
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../13_pretrain_strat/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    13. Pre-training Strategies
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../14_finetuning/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    14. Fine-tuning
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../15_cot/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    15. Chain of Thought Reasoning
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../16_nlg/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    16. Nature Language Generation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../17_imp_nlg/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    17. Improving Generation and Training for NLG
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../18_eval_nlu/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    18. Evaluation of NLU Systems
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../19_eval_nlg/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    19. Evaluation of NLG Systems
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../20_post_training/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    20. Post-training
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    21. Advanced Topics in Language Modelling
    
  </span>
  

      </a>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../22_llm_training_basics/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    22. LLM Training Basics
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../23_reasoning/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    23. Reasoning in LLMs
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../print_page/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Print/PDF
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
    <a href="https://github.com/SalK91/edit/main/docs/nlp/21_advanced_topics.md" title="Edit this page" class="md-content__button md-icon" rel="edit">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"></path></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/SalK91/raw/main/docs/nlp/21_advanced_topics.md" title="View source of this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"></path></svg>
    </a>
  


<h1 id="advanced-topics-in-language-modelling">Advanced Topics in Language Modelling<a class="headerlink" href="#advanced-topics-in-language-modelling" title="Permanent link">¶</a></h1>
<h2 id="knowledge-distillation-for-language-models">Knowledge Distillation for Language Models<a class="headerlink" href="#knowledge-distillation-for-language-models" title="Permanent link">¶</a></h2>
<p>Knowledge distillation is a model compression and capability transfer technique in NLP and LLMs that trains a compact student model to approximate a high-capacity teacher model. Instead of learning only from one-hot labels, the student also learns from the teacher’s soft predictive distribution and, optionally, its intermediate reasoning samples, improving both generalization and reliability while reducing inference cost.</p>
<h3 id="teacher-and-student-distributions">Teacher and Student Distributions<a class="headerlink" href="#teacher-and-student-distributions" title="Permanent link">¶</a></h3>
<p>Given input <span class="arithmatex">\(x\)</span>, the teacher outputs logits <span class="arithmatex">\(z_t \in \mathbb{R}^{|V|}\)</span> over vocabulary <span class="arithmatex">\(V\)</span>. A temperature-scaled softmax produces softened probabilities:</p>
<div class="arithmatex">\[
p_t^T = softmax(z_t / T), \quad T &gt; 1
\]</div>
<p>The student model generates its own logits <span class="arithmatex">\(z_s\)</span> and corresponding distribution:</p>
<div class="arithmatex">\[
p_s^T = softmax(z_s / T)
\]</div>
<p>When <span class="arithmatex">\(T &gt; 1\)</span>, distributions become smoother, exposing relationships between alternative token choices. This is critical for multi-step reasoning, where each token builds on implicit intermediate deductions. Distillation transfers not only correct answers but also richer decision structure and uncertainty.</p>
<h3 id="distillation-loss">Distillation Loss<a class="headerlink" href="#distillation-loss" title="Permanent link">¶</a></h3>
<p>Training minimizes a weighted objective balancing:</p>
<ul>
<li>Correctness using cross-entropy with ground truth <span class="arithmatex">\(y\)</span></li>
<li>Imitation using KL divergence between teacher and student distributions</li>
</ul>
<p>Loss formulation:</p>
<div class="arithmatex">\[
L = \alpha T^2 \, KL(p_t^T \| p_s^T) + (1 - \alpha) \, CE(y, softmax(z_s))
\]</div>
<p>Where:</p>
<div class="arithmatex">\[
KL(p \| q) = \sum_i p_i \log \frac{p_i}{q_i}
\]</div>
<p>The term <span class="arithmatex">\(T^2\)</span> rescales gradients to preserve signal magnitude when using high temperature, preventing vanishing updates.</p>
<h3 id="representation-alignment-encoder-models">Representation Alignment (Encoder Models)<a class="headerlink" href="#representation-alignment-encoder-models" title="Permanent link">¶</a></h3>
<p>For encoder models, teacher and student hidden states <span class="arithmatex">\(h_t\)</span> and <span class="arithmatex">\(h_s\)</span> may differ in size. A learned projector <span class="arithmatex">\(W\)</span> aligns them:</p>
<div class="arithmatex">\[
L_{rep} = MSE(h_t W, h_s)
\]</div>
<p>Alternative alignment objectives include cosine similarity or attention map matching across selected layers <span class="arithmatex">\(\mathcal{L}_k\)</span>.</p>
<h3 id="distillation-algorithm">Distillation Algorithm<a class="headerlink" href="#distillation-algorithm" title="Permanent link">¶</a></h3>
<h4 id="initial-setup">Initial Setup<a class="headerlink" href="#initial-setup" title="Permanent link">¶</a></h4>
<ul>
<li>Teacher Model: Large LM (e.g., 3.7B–175B parameters)</li>
<li>Student Model: Smaller LM (e.g., 125M–1.3B parameters)</li>
<li>Training Inputs: <span class="arithmatex">\(\mathcal{D}_{Train} = \{x_i\}\)</span></li>
<li>Prompt Set: <span class="arithmatex">\(P = \{(x_i, y_i, z_i)\}\)</span> where <span class="arithmatex">\(z_i\)</span> are teacher reasoning samples</li>
</ul>
<h4 id="sampling-process">Sampling Process<a class="headerlink" href="#sampling-process" title="Permanent link">¶</a></h4>
<p>For each example <span class="arithmatex">\(x_i\)</span>:</p>
<ol>
<li>Sample <span class="arithmatex">\(N\)</span> teacher reasoning–prediction pairs:
   <script type="math/tex; mode=display">
   (\hat{y}_i, \hat{z}_i) \sim \mathcal{N}_T(y_i, z_i \mid x_i, P)
   </script>
</li>
<li>Construct sample set:
   <script type="math/tex; mode=display">
   P_i = \{(x_i, \hat{z}_i^j, \hat{y}_i^j)\}_{j=1}^N
   </script>
</li>
<li>Typical setting:
   <script type="math/tex; mode=display">
   N = 30
   </script>
</li>
</ol>
<p>Create corpus:</p>
<div class="arithmatex">\[
C = \{(x_i, (\hat{z}_i^j, \hat{y}_i^j))\}_{j=1}^N
\]</div>
<h4 id="training-process">Training Process<a class="headerlink" href="#training-process" title="Permanent link">¶</a></h4>
<p>Train student on teacher samples using LM objective:</p>
<div class="arithmatex">\[
L(z_s, y_s \mid C) = CE(\hat{y}_i^j, \hat{z}_i^j \mid x_i)
\]</div>
<p>This objective integrates into the full distillation loss defined earlier.</p>
<h4 id="evaluation-options">Evaluation Options<a class="headerlink" href="#evaluation-options" title="Permanent link">¶</a></h4>
<p>After training, evaluate output quality using:</p>
<ul>
<li>
<p>Greedy Decoding
  <script type="math/tex; mode=display">
  (\hat{z}_{test}, \hat{y}_{test}) = argmax_{z_s} \mathcal{S}(y \mid z_t)
  </script>
</p>
</li>
<li>
<p>Self-Consistency
  <script type="math/tex; mode=display">
  \hat{y}_{test} = argmax_y \, \mathbb{E}_{z_s \sim \mathcal{S}_{top-k}} [\mathcal{S}(y \mid z_s, z_{test})]
  </script>
</p>
</li>
</ul>
<h4 id="optional-generative-extension-sample-and-rank">Optional Generative Extension: Sample-and-Rank<a class="headerlink" href="#optional-generative-extension-sample-and-rank" title="Permanent link">¶</a></h4>
<ol>
<li>Sample <span class="arithmatex">\(n\)</span> teacher completions per prompt</li>
<li>Score using reward model or teacher log-likelihood</li>
<li>Select top-<span class="arithmatex">\(k\)</span> sequences <span class="arithmatex">\(\mathcal{S}_{top}\)</span></li>
<li>Train student via:</li>
<li><span class="arithmatex">\(CE(\mathcal{S}_{top}, p_{student})\)</span>, or</li>
<li>policy distillation on teacher action distributions</li>
</ol>
<hr>
<h2 id="mixture-of-experts">Mixture of Experts<a class="headerlink" href="#mixture-of-experts" title="Permanent link">¶</a></h2>
<p>In LLMs and NLP, mixture of experts (MoE) replaces dense feed-forward layers with a set of expert networks <span class="arithmatex">\(\{E_1, ..., E_N\}\)</span> and a router <span class="arithmatex">\(G\)</span> that selects a sparse subset of experts per token. Given input representation <span class="arithmatex">\(h\)</span>, the router outputs gating logits <span class="arithmatex">\(r = G(h)\)</span> and expert selection is typically top-<span class="arithmatex">\(k\)</span>:</p>
<div class="arithmatex">\[
g_i = softmax(r)_i,\quad \mathcal{I} = topk(r, k)
\]</div>
<p>Only experts in <span class="arithmatex">\(\mathcal{I}\)</span> are executed, producing <span class="arithmatex">\(e_i = E_i(h)\)</span>, and the MoE layer output is:</p>
<div class="arithmatex">\[
y = \sum_{i \in \mathcal{I}} g_i \, e_i
\]</div>
<p>Training minimizes the task loss <span class="arithmatex">\(L_{task}\)</span> (e.g., next-token cross-entropy) plus auxiliary load-balancing and routing regularization to prevent expert collapse and imbalance. A common load-balancing loss uses batch-level expert utilization <span class="arithmatex">\(f_i\)</span> and mean gate probability <span class="arithmatex">\(\bar{g}_i\)</span>:</p>
<div class="arithmatex">\[
L = L_{task} + \lambda \sum_{i=1}^N f_i \cdot \bar{g}_i
\]</div>
<p>Alternative formulations use entropy bonuses on <span class="arithmatex">\(g\)</span>, z-loss on router logits, or differentiable routing approximations.</p>
<p>Algorithm steps:</p>
<ol>
<li>Replace MLP layers with MoE block containing <span class="arithmatex">\(N\)</span> experts and router <span class="arithmatex">\(G\)</span>.</li>
<li>For each token, compute router logits <span class="arithmatex">\(r = G(h)\)</span>.</li>
<li>Select expert indices <span class="arithmatex">\(\mathcal{I} = topk(r, k)\)</span>.</li>
<li>Compute gates <span class="arithmatex">\(g_i = softmax(r)_i\)</span> for <span class="arithmatex">\(i \in \mathcal{I}\)</span>.</li>
<li>Execute selected experts <span class="arithmatex">\(e_i = E_i(h)\)</span>.</li>
<li>Aggregate <span class="arithmatex">\(y = \sum_{i \in \mathcal{I}} g_i \, e_i\)</span>.</li>
<li>Compute loss <span class="arithmatex">\(L = L_{task} + L_{aux}\)</span> and backprop to student and router.</li>
<li>Optionally apply capacity limits per expert, expert dropout, router jitter noise, or switch to single-expert routing (top-1) variants.</li>
</ol>
<p>Efficiency note: MoE increases parameter count while reducing per-token FLOPs via sparse routing, improving scaling at controlled inference cost.</p>
<hr>
<h2 id="predicting-the-next-token-in-language-models">Predicting the Next Token in Language Models<a class="headerlink" href="#predicting-the-next-token-in-language-models" title="Permanent link">¶</a></h2>
<ol>
<li>
<p>Greedy Decoding: Greedy decoding selects the token with the highest predicted probability at each step: </p>
<div class="arithmatex">\[x_{t+1} = \arg\max_{x} \, p(x \mid x_{1:t})\]</div>
<p>While simple and efficient, it often produces suboptimal sequences that are repetitive, lack diversity, or fail to capture long-range coherence, since it ignores alternative plausible continuations.</p>
</li>
<li>
<p>Beam Search: Beam search maintains the top-<span class="arithmatex">\(k\)</span> most probable partial sequences (beams) at each timestep. The algorithm expands each beam with all possible next tokens, retains the <span class="arithmatex">\(k\)</span> highest-scoring sequences, and repeats until termination. Benefits include higher likelihood sequences compared to greedy decoding, but beam search increases computational cost and can still lack diversity, often producing deterministic or generic outputs if the beam width is small or length penalties are not applied.</p>
</li>
<li>
<p>Sampling-Based Decoding: Sampling introduces stochasticity to token selection, enabling more diverse and natural outputs. Common strategies include:  </p>
<ul>
<li>
<p>Top-<span class="arithmatex">\(k\)</span> sampling: Restrict the candidate set to the <span class="arithmatex">\(k\)</span> most probable tokens and sample according to their normalized probabilities.  </p>
<div class="arithmatex">\[p'(x \mid x_{1:t}) = \frac{p(x \mid x_{1:t})}{\sum_{i \in topk} p(i \mid x_{1:t})}, \quad x \sim p'\]</div>
</li>
<li>
<p>Top-<span class="arithmatex">\(p\)</span> (nucleus) sampling: Select the smallest set of tokens whose cumulative probability exceeds a threshold <span class="arithmatex">\(p\)</span> and sample from this set.  </p>
<div class="arithmatex">\[\mathcal{V}_p = \min \{V' \mid \sum_{i \in V'} p(i \mid x_{1:t}) \ge p \}, \quad x \sim p(i \mid i \in \mathcal{V}_p)\]</div>
</li>
<li>
<p>Temperature scaling: Adjusts the sharpness of the predicted distribution to control randomness:  </p>
</li>
</ul>
<div class="arithmatex">\[p_T(x \mid x_{1:t}) = softmax \left( \frac{\log p(x \mid x_{1:t})}{T} \right)\]</div>
<p>Low temperatures (<span class="arithmatex">\(T&lt;1\)</span>) make the distribution peakier, favoring high-probability tokens and reducing diversity. High temperatures (<span class="arithmatex">\(T&gt;1\)</span>) flatten the distribution, increasing randomness and creative outputs.</p>
</li>
</ol>
<p>Overall, the choice of decoding strategy involves a tradeoff between likelihood, diversity, and computational efficiency. Greedy and beam search optimize for probability, whereas sampling-based methods enhance diversity and naturalness in generated text.</p>
<hr>
<h2 id="inference-optimization-in-llms">Inference Optimization in LLMs<a class="headerlink" href="#inference-optimization-in-llms" title="Permanent link">¶</a></h2>
<h3 id="kv-caching">KV caching<a class="headerlink" href="#kv-caching" title="Permanent link">¶</a></h3>
<p>In autoregressive transformers, each new token attends to all prior tokens. Instead of recomputing past key/value projections, we cache them. For token step <span class="arithmatex">\(t\)</span>, the attention computation becomes:</p>
<div class="arithmatex">\[
Q_t = W_Q h_t,\quad K_{1:t} = [K_{cache}; W_K h_t],\quad V_{1:t} = [V_{cache}; W_V h_t]
\]</div>
<div class="arithmatex">\[
A_t = softmax\left(\frac{Q_t K_{1:t}^\top}{\sqrt{d_k}}\right) V_{1:t}
\]</div>
<p>The cache stores <span class="arithmatex">\((K_{1:t-1}, V_{1:t-1})\)</span> from earlier steps. This reduces per-token FLOPs from <span class="arithmatex">\(O(t)\)</span> to <span class="arithmatex">\(O(1)\)</span> for projections, leaving only the attention dot product with cached states. Latency improves significantly for long contexts, at the cost of <span class="arithmatex">\(O(n_{layers} · seq_{len} · d_{kv})\)</span> memory.</p>
<p>Algorithm steps:</p>
<ol>
<li>For each layer, compute <span class="arithmatex">\(K = W_K h, V = W_V h\)</span> for prompt tokens.</li>
<li>Store <span class="arithmatex">\((K, V)\)</span> in cache.</li>
<li>During generation, compute only <span class="arithmatex">\(K_t, V_t\)</span> for the new token.</li>
<li>Append to cache and attend using the full cached <span class="arithmatex">\(K, V\)</span>.</li>
</ol>
<h3 id="multi-query-attention-mqa-and-grouped-query-attention-gqa">Multi-Query Attention (MQA) and Grouped-Query Attention (GQA)<a class="headerlink" href="#multi-query-attention-mqa-and-grouped-query-attention-gqa" title="Permanent link">¶</a></h3>
<p>MQA shares a single key/value head across all query heads, reducing memory and bandwidth:</p>
<p>
<script type="math/tex; mode=display">
   K = W_K h,\quad V = W_V h \quad \text{(1 shared head)}
   </script>
</p>
<p>All query heads attend to the same <span class="arithmatex">\(K, V\)</span>. This cuts cache size by <span class="arithmatex">\(h\)</span>× (number of Q heads).<br>
   GQA generalizes this by sharing <span class="arithmatex">\(K, V\)</span> across groups of query heads:</p>
<p>
<script type="math/tex; mode=display">
   \mathcal{G}_j = \{Q_{j,1},...,Q_{j,m}\},\quad K_j, V_j \text{ shared per group}
   </script>
</p>
<p>If there are <span class="arithmatex">\(h_q\)</span> query heads and <span class="arithmatex">\(h_{kv}\)</span> KV heads, each KV head serves <span class="arithmatex">\(h_q / h_{kv}\)</span> query heads. GQA balances quality and efficiency better than full sharing (MQA) while still reducing memory bandwidth and cache footprint.</p>
<p>Benefits:</p>
<ul>
<li>Smaller KV cache (<span class="arithmatex">\(↓\)</span> memory, <span class="arithmatex">\(↓\)</span> GPU bandwidth pressure)</li>
<li>Faster decoding, especially in memory-bound regimes</li>
<li>Better quality than MQA when <span class="arithmatex">\(h_{kv} &gt; 1\)</span></li>
</ul>
<p>Limitations:</p>
<ul>
<li>Some capacity loss from reduced key/value specialization</li>
<li>Requires careful grouping choice to avoid quality drop</li>
</ul>
<h3 id="pagedattention">PagedAttention<a class="headerlink" href="#pagedattention" title="Permanent link">¶</a></h3>
<p>Standard KV caches allocate contiguous memory per sequence, causing fragmentation and over-allocation when sequences vary in length. PagedAttention stores KV blocks in fixed-size pages (like virtual memory), allowing non-contiguous storage:</p>
<p>Idea:</p>
<ul>
<li>Preallocate memory into pages of size <span class="arithmatex">\(P\)</span>.</li>
<li>Store <span class="arithmatex">\((K, V)\)</span> in page slots, not one long tensor.</li>
<li>Map logical token positions → physical page addresses.</li>
</ul>
<p>Memory model:</p>
<p>
<script type="math/tex; mode=display">
   (K, V)_{layer} \in \mathbb{R}^{n_{pages} × P × d_{kv}}
   </script>
</p>
<p>Attention reads KV by gathering relevant pages:</p>
<p>
<script type="math/tex; mode=display">
   A_t = softmax\left(\frac{Q_t K_{pages}^\top}{\sqrt{d_k}}\right) V_{pages}
   </script>
</p>
<p>Benefits:</p>
<ul>
<li>Eliminates wasted padding memory</li>
<li>Enables large-batch serving without OOM</li>
<li>Efficient for dynamic and very long contexts</li>
<li>Reduces fragmentation and improves throughput</li>
</ul>
<p>Algorithm steps:</p>
<ol>
<li>Partition prompt tokens into pages of length <span class="arithmatex">\(P\)</span>.</li>
<li>Store each page’s <span class="arithmatex">\(K, V\)</span> into free page slots.</li>
<li>Maintain a page table mapping token index → page slot.</li>
<li>During decoding, gather only required pages for attention.</li>
<li>Append new token KV into next free page.</li>
</ol>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"></path></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer">
        
          
          <a href="../20_post_training/" class="md-footer__link md-footer__link--prev" aria-label="Previous: 20. Post-training">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                20. Post-training
              </div>
            </div>
          </a>
        
        
          
          <a href="../22_llm_training_basics/" class="md-footer__link md-footer__link--next" aria-label="Next: 22. LLM Training Basics">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                22. LLM Training Basics
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"></path></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      © 2025 Salman Khan — Educational Use Only
    </div>
  
  
</div>
      
        
<div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/SalK91/reinforcement_learning" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"></path></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.tabs", "navigation.sections", "navigation.expand", "navigation.indexes", "navigation.path", "navigation.top", "navigation.footer", "toc.follow", "content.code.copy", "content.action.edit", "content.action.view", "search.suggest", "search.highlight"], "search": "../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
        <script src="../../js/print-site.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
      
    
  
<script id="init-glightbox">const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(()=>{ lightbox.reload(); });
</script></body></html>